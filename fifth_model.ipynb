{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP26Iph87w2vyFxN3HWGTo0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profsuccodifrutta/Variational_Autoencoder_for_Anomaly_Detection/blob/main/fifth_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dtw_7NW5AdDk"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea una cartella locale su Colab per i dati (veloce)\n",
        "!mkdir -p /content/dataset_local\n",
        "\n",
        "# Scompatta il file.\n",
        "path_zip = \"/content/drive/MyDrive/brainmri.zip\"\n",
        "\n",
        "!unzip -o -q \"{path_zip}\" -d /content/dataset_local\n",
        "\n",
        "print(\"Scompattamento completato!\")\n",
        ""
      ],
      "metadata": {
        "id": "b57H0AuTAlER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "59D1DlcyAlRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "OOaoGVjBAlcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file_sani = glob.glob(\"/content/dataset_local/**/Training/notumor/*.jpg\", recursive=True)\n",
        "print(f\"--- ANALISI DATASET ---\")\n",
        "print(f\"Totale immagini sane trovate: {len(file_sani)}\")\n",
        "\n",
        "class BrainDataset(Dataset):\n",
        "    def __init__(self, file_list, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_list[idx]\n",
        "        image = Image.open(img_path).convert('L') # Scala di grigi\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "# 70% Train, 20% Val, 10% Test\n",
        "if len(file_sani) > 0:\n",
        "    full_healthy_ds = BrainDataset(file_sani)\n",
        "\n",
        "    train_size = int(0.7 * len(full_healthy_ds))\n",
        "    val_size = int(0.2 * len(full_healthy_ds))\n",
        "    test_size = len(full_healthy_ds) - train_size - val_size\n",
        "\n",
        "    train_subset, val_subset, test_healthy_subset = random_split(\n",
        "        full_healthy_ds, [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "\n",
        "    # Recupero anomalie per il Test finale\n",
        "    file_anomalie = glob.glob(\"/content/dataset_local/**/Testing/*/*.jpg\", recursive=True)\n",
        "    file_anomalie = [f for f in file_anomalie if \"notumor\" not in f]\n",
        "\n",
        "    print(f\"Training: {len(train_subset)} | Val: {len(val_subset)} | Test Sani: {len(test_healthy_subset)}\")\n",
        "    print(f\"Anomalie trovate per test: {len(file_anomalie)}\")\n",
        "else:\n",
        "    print(\"ERRORE: Dataset non trovato.\")"
      ],
      "metadata": {
        "id": "7V0jLQ1wAllz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. CONFIGURAZIONE TRASFORMAZIONI\n",
        "# Rimuoviamo la normalizzazione mean/std per usare il range [0, 1] compatibile con Sigmoid\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),       # Resize diretto a 224\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),               # Porta i pixel da [0, 255] a [0.0, 1.0]\n",
        "])\n",
        "\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    BrainDataset([train_subset.dataset.file_list[i] for i in train_subset.indices], transform=train_transform),\n",
        "    batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    BrainDataset([val_subset.dataset.file_list[i] for i in val_subset.indices], transform=base_transform),\n",
        "    batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Test loaders\n",
        "test_loader_sani = DataLoader(\n",
        "    BrainDataset([test_healthy_subset.dataset.file_list[i] for i in test_healthy_subset.indices], transform=base_transform),\n",
        "    batch_size=batch_size, shuffle=False)\n",
        "\n",
        "anno_loader = DataLoader(\n",
        "    BrainDataset(file_anomalie, transform=base_transform),\n",
        "    batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\" Configurazione completata. Batch size: {batch_size}\")"
      ],
      "metadata": {
        "id": "ReCdPMWWAlvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(in_channels)\n",
        "        )\n",
        "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(x + self.conv(x))\n",
        "\n",
        "class VAE_V5(nn.Module):\n",
        "    def __init__(self, latent_dim=1024):\n",
        "        super(VAE_V5, self).__init__()\n",
        "\n",
        "        # ENCODER: 224x224 -> 112x112 -> 56x56 -> 28x28 -> 14x14 -> 7x7\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, stride=2, padding=1), # 112\n",
        "            nn.BatchNorm2d(32), nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, stride=2, padding=1), # 56\n",
        "            nn.BatchNorm2d(64), nn.LeakyReLU(0.2),\n",
        "            ResBlock(64),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1), # 28\n",
        "            nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
        "            ResBlock(128),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1), # 14\n",
        "            nn.BatchNorm2d(256), nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 256, 3, stride=2, padding=1), # 7x7\n",
        "            nn.BatchNorm2d(256), nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.flatten_dim = 256 * 7 * 7 # 12.544 (molto più gestibile di 100k!)\n",
        "        self.fc_mu = nn.Linear(self.flatten_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(self.flatten_dim, latent_dim)\n",
        "\n",
        "        # DECODER\n",
        "        self.decoder_input = nn.Linear(latent_dim, self.flatten_dim)\n",
        "        self.unflatten = nn.Unflatten(1, (256, 7, 7))\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 256, 3, stride=2, padding=1, output_padding=1), # 14\n",
        "            nn.BatchNorm2d(256), nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1), # 28\n",
        "            nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
        "            ResBlock(128),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # 56\n",
        "            nn.BatchNorm2d(64), nn.LeakyReLU(0.2),\n",
        "            ResBlock(64),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 112\n",
        "            nn.BatchNorm2d(32), nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(32, 1, 3, stride=2, padding=1, output_padding=1), # 224\n",
        "            nn.Sigmoid() # Output in [0, 1] per matchare i nuovi dati\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        h = torch.flatten(h, start_dim=1)\n",
        "        mu, logvar = self.fc_mu(h), self.fc_logvar(h)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_recon = self.decoder(self.unflatten(self.decoder_input(z)))\n",
        "        return x_recon, mu, logvar"
      ],
      "metadata": {
        "id": "6xFBWcWJC2tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def ssim_loss(img1, img2, window_size=11):\n",
        "    mu1 = F.avg_pool2d(img1, window_size, stride=1, padding=window_size//2)\n",
        "    mu2 = F.avg_pool2d(img2, window_size, stride=1, padding=window_size//2)\n",
        "\n",
        "    sigma1_sq = F.avg_pool2d(img1 * img1, window_size, stride=1, padding=window_size//2) - mu1.pow(2)\n",
        "    sigma2_sq = F.avg_pool2d(img2 * img2, window_size, stride=1, padding=window_size//2) - mu2.pow(2)\n",
        "    sigma12 = F.avg_pool2d(img1 * img2, window_size, stride=1, padding=window_size//2) - (mu1 * mu2)\n",
        "\n",
        "    c1, c2 = 0.01**2, 0.03**2 # Costanti di stabilità\n",
        "\n",
        "    num = (2 * mu1 * mu2 + c1) * (2 * sigma12 + c2)\n",
        "    den = (mu1.pow(2) + mu2.pow(2) + c1) * (sigma1_sq + sigma2_sq + c2)\n",
        "\n",
        "    return 1 - (num / den).mean()\n",
        "\n",
        "def loss_function(recon_x, x, mu, logvar, beta=0.01):\n",
        "    #  BCE (Pixel intensity)\n",
        "    # reduction='sum' diviso per batch_size mantiene i valori stabili\n",
        "    bce = F.binary_cross_entropy(recon_x, x, reduction='sum') / x.shape[0]\n",
        "\n",
        "    #  SSIM (Structural integrity)\n",
        "    # Moltiplichiamo per 500-1000 per bilanciarla con la scala della BCE\n",
        "    ssim = ssim_loss(recon_x, x) * 1000\n",
        "\n",
        "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.shape[0]\n",
        "\n",
        "    total_loss = bce + ssim + (beta * kl)\n",
        "\n",
        "    return total_loss, bce, kl"
      ],
      "metadata": {
        "id": "wH7f4OUyD-gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "latent_dim = 1024\n",
        "model = VAE_V5(latent_dim=latent_dim).to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5) # lr cauto\n",
        "\n",
        "# Scheduler: Riduce il LR del 50% (factor=0.5) se la Val Loss non migliora per 5 epoche\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n"
      ],
      "metadata": {
        "id": "yDxrezxmF0dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_reconstruction(model, val_loader, device, epoch):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # batch dal loader di validazione\n",
        "        inputs = next(iter(val_loader))\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        # Ricostruzione\n",
        "        recons, mu, logvar = model(inputs)\n",
        "\n",
        "        # su cpu per plottare\n",
        "        img = inputs[0].cpu().squeeze().numpy()\n",
        "        recon = recons[0].cpu().squeeze().numpy()\n",
        "\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.title(\"Originale\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(recon, cmap='gray')\n",
        "        plt.title(f\"Ricostruzione Epoca {epoch+1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "5oCQvg26Htdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# training loop\n",
        "\n",
        "def train_vae(model, train_loader, val_loader, optimizer, scheduler, num_epochs):\n",
        "    train_history = {'total': [], 'recon': [], 'kl': []}\n",
        "    val_history = {'total': [], 'recon': [], 'kl': []}\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        current_beta = min(target_beta, target_beta * (epoch / warmup_epochs))\n",
        "\n",
        "        train_total, train_recon, train_kl = 0, 0, 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            recon_batch, mu, logvar = model(batch)\n",
        "\n",
        "            loss, r_loss, k_loss = loss_function(recon_batch, batch, mu, logvar, beta=current_beta)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_total += loss.item()\n",
        "            train_recon += r_loss.item()\n",
        "            train_kl += k_loss.item()\n",
        "\n",
        "        # VALIDAZIONE\n",
        "        model.eval()\n",
        "        val_total, val_recon, val_kl = 0, 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                recon_batch, mu, logvar = model(batch)\n",
        "                loss, r_loss, k_loss = loss_function(recon_batch, batch, mu, logvar, beta=current_beta)\n",
        "\n",
        "                val_total += loss.item()\n",
        "                val_recon += r_loss.item()\n",
        "                val_kl += k_loss.item()\n",
        "\n",
        "        # Calcolo medie per epoca\n",
        "        avg_train_loss = train_total / len(train_loader)\n",
        "        avg_val_loss = val_total / len(val_loader)\n",
        "\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Salvataggio storia\n",
        "        train_history['total'].append(avg_train_loss)\n",
        "        val_history['total'].append(avg_val_loss)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Beta: {current_beta:.5f} | \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), '/content/drive/MyDrive/VAE_Brain_Project/best_model_v4.pth')\n",
        "            print(\" Miglior modello salvato!\")\n",
        "\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"\\n--- Visualizzazione Ricostruzione (Epoca {epoch+1}) ---\")\n",
        "            plot_reconstruction(model, val_loader, device, epoch)\n",
        "\n",
        "            plt.figure(figsize=(8, 4))\n",
        "            plt.plot(train_history['total'], label='Train Loss')\n",
        "            plt.plot(val_history['total'], label='Val Loss')\n",
        "            plt.title(f\"Andamento Loss fino a Epoca {epoch+1}\")\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "    return train_history, val_history\n",
        "\n",
        "# Esecuzione\n",
        "# history = train_vae(model, train_loader, val_loader, optimizer, scheduler, num_epochs)"
      ],
      "metadata": {
        "id": "tebDyvmyGDIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "num_epochs = 80\n",
        "target_beta = 0.005\n",
        "warmup_epochs = 20\n",
        "\n",
        "history_train, history_val = train_vae(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=num_epochs\n",
        ")"
      ],
      "metadata": {
        "id": "4WEA1cDfJpTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CARICAMENTO MODELLO\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "latent_dim = 1024\n",
        "model = VAE_V5(latent_dim=latent_dim).to(device)\n",
        "\n",
        "model_path_v5 = \"/content/drive/MyDrive/VAE_Brain_Project/best_model_v5.pth\"\n",
        "\n",
        "try:\n",
        "    checkpoint = torch.load(model_path_v5, map_location=device)\n",
        "    model.load_state_dict(checkpoint)\n",
        "    model.eval()\n",
        "    print(f\" Modello V5 caricato correttamente!\")\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\" Capacità: {total_params:,} parametri.\")\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\" Errore: Il file '{model_path_v5}' non esiste.\")\n",
        "    print(\"Controlla se il nome del file o il percorso nel Drive sono corretti.\")\n",
        "except RuntimeError as e:\n",
        "    print(f\" Errore di architettura: Incompatibilità rilevata.\")\n",
        "    print(\"Assicurati di non aver modificato la classe VAE_V5 rispetto a quando hai salvato i pesi.\")"
      ],
      "metadata": {
        "id": "KWN8OQA5LsEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logica per la classificazione\n",
        "def get_anomaly_scores(model, loader, device):\n",
        "    model.eval()\n",
        "    scores = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            recon, _, _ = model(batch)\n",
        "            # bce loss as anomaly score\n",
        "            bce_per_pixel = F.binary_cross_entropy(recon, batch, reduction='none')\n",
        "            img_error = torch.mean(bce_per_pixel, dim=(1, 2, 3))\n",
        "\n",
        "            scores.extend(img_error.cpu().numpy())\n",
        "    return np.array(scores)"
      ],
      "metadata": {
        "id": "etSeBMH2Pulh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
        "                             roc_curve, ConfusionMatrixDisplay, accuracy_score, f1_score, recall_score)\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "test_healthy_scores = get_anomaly_scores(model, test_loader_sani, device)\n",
        "test_anomaly_scores = get_anomaly_scores(model, anno_loader, device)\n",
        "\n",
        "y_true = np.array([0] * len(test_healthy_scores) + [1] * len(test_anomaly_scores))\n",
        "y_scores = np.concatenate([test_healthy_scores, test_anomaly_scores])\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "auc_value = roc_auc_score(y_true, y_scores)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "y_pred = [1 if s > optimal_threshold else 0 for s in y_scores]\n",
        "\n",
        "acc_modello = accuracy_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "conteggio_classi = np.bincount(y_true)\n",
        "nir = np.max(conteggio_classi) / len(y_true)\n",
        "\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "# ROC Curve\n",
        "ax1.plot(fpr, tpr, color='darkred', lw=2, label=f'AUC = {auc_value:.3f}')\n",
        "ax1.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "ax1.scatter(fpr[optimal_idx], tpr[optimal_idx], color='black', label='Soglia Ottimale')\n",
        "ax1.set_title('ROC Curve (Capacità Discriminativa)')\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate')\n",
        "ax1.legend(loc=\"lower right\")\n",
        "\n",
        "# Istogramma Distribuzione\n",
        "ax2.hist(test_healthy_scores, bins=30, alpha=0.6, label='Sani (Normali)', color='green', density=True)\n",
        "ax2.hist(test_anomaly_scores, bins=30, alpha=0.6, label='Anomalie (Tumori)', color='red', density=True)\n",
        "ax2.axvline(optimal_threshold, color='black', linestyle='--', label=f'Threshold: {optimal_threshold:.4f}')\n",
        "ax2.set_title('Distribuzione Errori di Ricostruzione (BCE)')\n",
        "ax2.set_xlabel('Anomaly Score')\n",
        "ax2.legend()\n",
        "\n",
        "# Matrice di Confusione\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Sano', 'Tumore'])\n",
        "disp.plot(ax=ax3, cmap='Reds', values_format='d')\n",
        "ax3.set_title('Matrice di Confusione')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# report finale\n",
        "print(f\"\\n\" + \"=\"*30)\n",
        "print(f\"   PERFORMANCE REPORT V5\")\n",
        "print(f\"=\"*30)\n",
        "print(f\"Accuracy:           {acc_modello:.4f}\")\n",
        "print(f\"F1-Score:           {f1:.4f} (Bilanciamento Prec/Rec)\")\n",
        "print(f\"Recall (Sensibilità): {recall:.4f} <-- IMPORTANTE\")\n",
        "print(f\"AUC Score:          {auc_value:.4f}\")\n",
        "print(f\"No Information Rate: {nir:.4f}\")\n",
        "print(f\"Soglia calcolata:    {optimal_threshold:.6f}\")\n",
        "print(\"-\" * 30)\n",
        "print(classification_report(y_true, y_pred, target_names=['Sano', 'Tumore']))"
      ],
      "metadata": {
        "id": "uyqEcIUxMPN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def visualize_mri_anomaly(model, loader_sani, loader_anno, device):\n",
        "    \"\"\"\n",
        "    Visualizza il confronto tra un cervello sano e uno con tumore,\n",
        "    mostrando l'errore di ricostruzione tramite heatmap BCE.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        img_sano = next(iter(loader_sani))[0:1].to(device)\n",
        "        img_anno = next(iter(loader_anno))[0:1].to(device)\n",
        "\n",
        "        # forward pass\n",
        "        rec_sano, _, _ = model(img_sano)\n",
        "        rec_anno, _, _ = model(img_anno)\n",
        "\n",
        "        # mappe errore bce puntuale\n",
        "        err_sano = F.binary_cross_entropy(rec_sano, img_sano, reduction='none').cpu().squeeze()\n",
        "        err_anno = F.binary_cross_entropy(rec_anno, img_anno, reduction='none').cpu().squeeze()\n",
        "\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "        score_sano = err_sano.mean().item()\n",
        "        score_anno = err_anno.mean().item()\n",
        "\n",
        "        # caso sano\n",
        "        axes[0,0].imshow(img_sano.cpu().squeeze(), cmap='gray')\n",
        "        axes[0,0].set_title(\"SANO: Originale\", fontsize=12)\n",
        "\n",
        "        axes[0,1].imshow(rec_sano.cpu().squeeze(), cmap='gray')\n",
        "        axes[0,1].set_title(\"SANO: Ricostruzione VAE\", fontsize=12)\n",
        "\n",
        "        im1 = axes[0,2].imshow(err_sano, cmap='hot')\n",
        "        axes[0,2].set_title(f\"SANO: Mappa Errore (Score: {score_sano:.5f})\", fontsize=12, fontweight='bold')\n",
        "        fig.colorbar(im1, ax=axes[0,2], fraction=0.046, pad=0.04)\n",
        "\n",
        "        # caso tumore\n",
        "        axes[1,0].imshow(img_anno.cpu().squeeze(), cmap='gray')\n",
        "        axes[1,0].set_title(\"TUMORE: Originale\", fontsize=12)\n",
        "\n",
        "        axes[1,1].imshow(rec_anno.cpu().squeeze(), cmap='gray')\n",
        "        axes[1,1].set_title(\"TUMORE: Ricostruzione VAE\", fontsize=12)\n",
        "\n",
        "        vmax_val = max(err_anno.max(), err_sano.max()) * 0.8\n",
        "        im2 = axes[1,2].imshow(err_anno, cmap='hot', vmax=vmax_val)\n",
        "        axes[1,2].set_title(f\"TUMORE: Mappa Errore (Score: {score_anno:.5f})\", fontsize=12, fontweight='bold', color='red')\n",
        "        fig.colorbar(im2, ax=axes[1,2], fraction=0.046, pad=0.04)\n",
        "\n",
        "        for ax in axes.flatten():\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.suptitle(f\"Analisi Qualitativa Anomaly Detection\", fontsize=16, y=0.95)\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "visualize_mri_anomaly(model, test_loader_sani, anno_loader, device)"
      ],
      "metadata": {
        "id": "foDu4NS4Ojfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# identifica immagini sane che il modello ha scambiato per tumori\n",
        "def analyze_false_positives(model, loader_sani, threshold, device, n_max=5):\n",
        "    model.eval()\n",
        "    fp_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader_sani:\n",
        "            batch = batch.to(device)\n",
        "            recon, _, _ = model(batch)\n",
        "\n",
        "            bce_per_img = F.binary_cross_entropy(recon, batch, reduction='none').mean(dim=(1,2,3))\n",
        "\n",
        "            # Falsi Positivi (Sani con Score > Soglia)\n",
        "            mask = bce_per_img > threshold\n",
        "            if mask.any():\n",
        "                indices = torch.where(mask)[0]\n",
        "                for idx in indices:\n",
        "                    fp_list.append({\n",
        "                        'img': batch[idx].cpu(),\n",
        "                        'rec': recon[idx].cpu(),\n",
        "                        'score': bce_per_img[idx].item()\n",
        "                    })\n",
        "\n",
        "    # ordine decrescente per errore\n",
        "    fp_list = sorted(fp_list, key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "    if not fp_list:\n",
        "        print(\" Non sono stati trovati Falsi Positivi nel set analizzato.\")\n",
        "        return\n",
        "\n",
        "    print(f\" Trovati {len(fp_list)} Falsi Positivi. Visualizzo i primi {min(n_max, len(fp_list))}:\")\n",
        "\n",
        "    # Plotting\n",
        "    n_plot = min(n_max, len(fp_list))\n",
        "    fig, axes = plt.subplots(n_plot, 3, figsize=(15, 5 * n_plot))\n",
        "\n",
        "    if n_plot == 1: axes = [axes] # Gestione caso singola immagine\n",
        "\n",
        "    for i in range(n_plot):\n",
        "        img = fp_list[i]['img'].squeeze()\n",
        "        rec = fp_list[i]['rec'].squeeze()\n",
        "        score = fp_list[i]['score']\n",
        "        err_map = torch.abs(img - rec)\n",
        "\n",
        "        axes[i][0].imshow(img, cmap='gray'); axes[i][0].set_title(f\"FP #{i+1} Originale\")\n",
        "        axes[i][1].imshow(rec, cmap='gray'); axes[i][1].set_title(f\"Ricostruzione (Fallita)\")\n",
        "        im = axes[i][2].imshow(err_map, cmap='magma'); axes[i][2].set_title(f\"Errore (Score: {score:.5f})\")\n",
        "        fig.colorbar(im, ax=axes[i][2])\n",
        "\n",
        "        for ax in axes[i]: ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "analyze_false_positives(model, test_loader_sani, optimal_threshold, device)"
      ],
      "metadata": {
        "id": "KotidOWhPyFH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}