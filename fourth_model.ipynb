{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6tKgMVOCDGkNVCJsba0OV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profsuccodifrutta/Variational_Autoencoder_for_Anomaly_Detection/blob/main/fourth_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GDuovzOHyni"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea una cartella locale su Colab per i dati (veloce)\n",
        "!mkdir -p /content/dataset_local\n",
        "\n",
        "# Scompatta il file.\n",
        "path_zip = \"/content/drive/MyDrive/brainmri.zip\"\n",
        "\n",
        "!unzip -o -q \"{path_zip}\" -d /content/dataset_local\n",
        "\n",
        "print(\"Scompattamento completato!\")"
      ],
      "metadata": {
        "id": "kZUA8AUnIwF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "MCeh_xMIK0xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "lvhRLU_oKHqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, random_split\n",
        "\n",
        "# puntatore dati sani\n",
        "file_sani = glob.glob(\"/content/dataset_local/**/Training/notumor/*.jpg\", recursive=True)\n",
        "\n",
        "print(f\"--- ANALISI DATASET ---\")\n",
        "print(f\"Totale immagini sane trovate: {len(file_sani)}\")\n",
        "\n",
        "#  Classe Dataset\n",
        "class BrainDataset(Dataset):\n",
        "    def __init__(self, file_list, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_list[idx]\n",
        "        image = Image.open(img_path).convert('L')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "#  Creazione Split (70% Train, 20% Val, 10% Test)\n",
        "if len(file_sani) > 0:\n",
        "    full_healthy_ds = BrainDataset(file_sani)\n",
        "\n",
        "    train_size = int(0.7 * len(full_healthy_ds))\n",
        "    val_size = int(0.2 * len(full_healthy_ds))\n",
        "    test_size = len(full_healthy_ds) - train_size - val_size\n",
        "\n",
        "    train_subset, val_subset, test_healthy_subset = random_split(\n",
        "        full_healthy_ds, [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "\n",
        "    print(f\"\\n--- DISTRIBUZIONE SPLIT (Solo Sani) ---\")\n",
        "    print(f\"‚úÖ Training:   {len(train_subset)} immagini (usate per imparare la normalit√†)\")\n",
        "    print(f\"‚ö†Ô∏è Validation: {len(val_subset)} immagini (usate per monitorare l'allenamento)\")\n",
        "    print(f\"üõ°Ô∏è Test Sani:  {len(test_healthy_subset)} immagini (usate per valutare i falsi allarmi)\")\n",
        "\n",
        "    #  Recupero anomalie per il Test finale\n",
        "    file_anomalie = glob.glob(\"/content/dataset_local/**/Testing/*/*.jpg\", recursive=True)\n",
        "    # Filtro via i sani dalla cartella Testing per avere solo anomalie vere\n",
        "    file_anomalie = [f for f in file_anomalie if \"notumor\" not in f]\n",
        "\n",
        "    print(f\"\\n--- DATI PER TEST ANOMALIE ---\")\n",
        "    print(f\"üö® Anomalie:  {len(file_anomalie)} immagini (glioma, meningioma, etc.)\")\n",
        "else:\n",
        "    print(\"‚ùå ERRORE: Non ho trovato le immagini. Controlla se la cartella 'Training/notumor' esiste.\")"
      ],
      "metadata": {
        "id": "KMjKKrM8Lda4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dimensione reale immagine dataset prima delle trasformazioni\n",
        "img_raw = Image.open(train_subset.dataset.file_list[0])\n",
        "print(f\"La dimensione originale dei file √®: {img_raw.size}\")"
      ],
      "metadata": {
        "id": "FOa7a0q2Rx3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Normalizzazione standard per MRI\n",
        "mri_mean = [0.45]\n",
        "mri_std = [0.22]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(232),              # Ridimensionamento\n",
        "    transforms.CenterCrop(224),          # ritaglio 4 pixel\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mri_mean, mri_std)\n",
        "])\n",
        "\n",
        "base_transform = transforms.Compose([\n",
        "    transforms.Resize(232),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mri_mean, mri_std)\n",
        "])\n",
        "\n",
        "# 3. CREAZIONE DEI DATALOADERS\n",
        "batch_size = 8\n",
        "\n",
        "# Recupero percorsi dai subset\n",
        "file_train_paths = [train_subset.dataset.file_list[i] for i in train_subset.indices]\n",
        "file_val_paths = [val_subset.dataset.file_list[i] for i in val_subset.indices]\n",
        "file_sani_test_paths = [test_healthy_subset.dataset.file_list[i] for i in test_healthy_subset.indices]\n",
        "\n",
        "# Inizializzazione Loader\n",
        "train_loader = DataLoader(BrainDataset(file_train_paths, transform=train_transform), batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(BrainDataset(file_val_paths, transform=base_transform), batch_size=batch_size, shuffle=False)\n",
        "test_loader_sani = DataLoader(BrainDataset(file_sani_test_paths, transform=base_transform), batch_size=batch_size, shuffle=False)\n",
        "anno_loader = DataLoader(BrainDataset(file_anomalie, transform=base_transform), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"‚úÖ Configurazione completata!\")\n",
        "print(f\"Train: {len(file_train_paths)} | Test Sani: {len(file_sani_test_paths)} | Anomalie: {len(file_anomalie)}\")"
      ],
      "metadata": {
        "id": "tjx5OX8jR-5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images = next(iter(train_loader))\n",
        "\n",
        "print(f\"Formato del batch (Batch_size, Canali, Altezza, Larghezza): {images.shape}\")\n",
        "\n",
        "#  prime 4 immagini per vedere l'effetto delle trasformazioni\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(4):\n",
        "    plt.subplot(1, 4, i+1)\n",
        "    # Squeeze serve per passare da (1, 128, 128) a (128, 128) per il plot\n",
        "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"Train Img {i+1}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yvv_PGXrSIoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(in_channels)\n",
        "        )\n",
        "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(x + self.conv(x))\n",
        "\n",
        "class VAE_V4(nn.Module):\n",
        "    def __init__(self, latent_dim=1024):\n",
        "        super(VAE_V4, self).__init__()\n",
        "\n",
        "        # ENCODER\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False), # 112x112\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            ResBlock(64),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False), # 56x56\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            ResBlock(128),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1, bias=False), # 28x28\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            ResBlock(256),\n",
        "\n",
        "            # COMPRESSIONE FILTRI: Da 256 a 128 prima del Flatten\n",
        "            nn.Conv2d(256, 128, kernel_size=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.flatten_dim = 128 * 28 * 28 # 100.352\n",
        "        self.fc_mu = nn.Linear(self.flatten_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(self.flatten_dim, latent_dim)\n",
        "\n",
        "        # DECODER\n",
        "        self.decoder_input = nn.Linear(latent_dim, self.flatten_dim)\n",
        "        self.unflatten = nn.Unflatten(1, (128, 28, 28))\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            # ESPANSIONE FILTRI: Da 128 a 256\n",
        "            nn.Conv2d(128, 256, kernel_size=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            ResBlock(256),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1, bias=False), # 56x56\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            ResBlock(128),\n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1, bias=False), # 112x112\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            ResBlock(64),\n",
        "            nn.ConvTranspose2d(64, 1, 7, stride=2, padding=3, output_padding=1, bias=False), # 224x224\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.apply(self._init_weights)\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
        "            # xavier per evitare saturazione prima della tahn\n",
        "            if m.out_channels == 1:\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "            else:\n",
        "                nn.init.kaiming_normal_(m.weight, a=0.2, mode='fan_out', nonlinearity='leaky_relu')\n",
        "\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            # Xavier per layer densi\n",
        "            nn.init.xavier_normal_(m.weight)\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            # Fondamentale per far partire bene la normalizzazione\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        h = torch.flatten(h, start_dim=1)\n",
        "        mu, logvar = self.fc_mu(h), self.fc_logvar(h)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "\n",
        "        x_recon = self.decoder(self.unflatten(self.decoder_input(z)))\n",
        "        return x_recon, mu, logvar"
      ],
      "metadata": {
        "id": "ti75_F5rTsLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "def loss_function(recon_x, x, mu, logvar, beta=0.01): # Beta aumentato\n",
        "    # MSE\n",
        "    recon_loss = F.mse_loss(recon_x, x, reduction='mean')\n",
        "\n",
        "    # KL Divergence\n",
        "    kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    # combinazione pesata\n",
        "    return recon_loss + (beta * kl_loss), recon_loss, kl_loss\n"
      ],
      "metadata": {
        "id": "m6n87wI_ZbpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_reconstruction(model, loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Funzione di utilit√† per invertire la normalizzazione (mri_std=0.22, mri_mean=0.45)\n",
        "        def denorm(x):\n",
        "            return (x * 0.22) + 0.45\n",
        "\n",
        "        # estrai batch\n",
        "        data = next(iter(loader))\n",
        "        data = data.to(device)\n",
        "\n",
        "        # Ottiene la ricostruzione\n",
        "        recon, _, _ = model(data)\n",
        "\n",
        "        # Plot dei primi 2 esempi\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
        "        for i in range(2):\n",
        "            # Originale (Denormalizzato e clippato tra 0 e 1)\n",
        "            img_orig = denorm(data[i]).cpu().squeeze().clamp(0, 1)\n",
        "            axes[i, 0].imshow(img_orig, cmap='gray')\n",
        "            axes[i, 0].set_title(\"Originale (V4-Zoom)\")\n",
        "            axes[i, 0].axis('off')\n",
        "\n",
        "            # Ricostruito (Denormalizzato e clippato tra 0 e 1)\n",
        "            img_recon = denorm(recon[i]).cpu().squeeze().clamp(0, 1)\n",
        "            axes[i, 1].imshow(img_recon, cmap='gray')\n",
        "            axes[i, 1].set_title(\"Ricostruzione V4\")\n",
        "            axes[i, 1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "DqDcJ5hO1NzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Istanza modello V4\n",
        "model = VAE_V4(latent_dim=1024).to(device)\n",
        "\n",
        "# Optimizer: LR a 5e-5 per gestire l'architettura profonda\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-5)\n",
        "\n",
        "#  Scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.5,\n",
        "    patience=5\n",
        ")\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "print(f\"‚úÖ Modello V4 inizializzato.\")\n",
        "print(f\"Parametri totali: {sum(p.numel() for p in model.parameters()):,}\")"
      ],
      "metadata": {
        "id": "xBZgu-IxpOeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import torch.nn.utils as utils\n",
        "\n",
        "# --- CONFIGURAZIONE V4 ---\n",
        "save_path_v4 = \"/content/drive/MyDrive/VAE_Brain_Project/best_model_v4.pth\"\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "beta_val = 0.01\n",
        "num_epochs = 100\n",
        "\n",
        "print(f\"Inizio Training V4 su {device}...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # TRAINING\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        recon, mu, logvar = model(batch)\n",
        "\n",
        "        loss, mse, kl = loss_function(recon, batch, mu, logvar, beta=beta_val)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient Clipping per stabilit√† con i Residual Blocks\n",
        "        utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train = train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train)\n",
        "\n",
        "    # FASE DI VALIDAZIONE\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = batch.to(device)\n",
        "            recon, mu, logvar = model(batch)\n",
        "            loss, _, _ = loss_function(recon, batch, mu, logvar, beta=beta_val)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val = val_loss / len(val_loader)\n",
        "    val_losses.append(avg_val)\n",
        "\n",
        "    # Aggiornamento Scheduler\n",
        "    scheduler.step(avg_val)\n",
        "\n",
        "    # Salvataggio miglior modello\n",
        "    if avg_val < best_val_loss:\n",
        "        best_val_loss = avg_val\n",
        "        torch.save(model.state_dict(), save_path_v4)\n",
        "        status_save = \" Miglior modello V4 salvato!\"\n",
        "    else:\n",
        "        status_save = \"\"\n",
        "\n",
        "    # VISUALIZZAZIONE OGNI 10 EPOCHE\n",
        "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "        #  Plot delle Loss\n",
        "        ax1.plot(train_losses, label='Train Loss')\n",
        "        ax1.plot(val_losses, label='Val Loss')\n",
        "        ax1.set_yscale('log')\n",
        "        ax1.set_title(f\"Loss Curve V4 (Epoca {epoch+1})\")\n",
        "        ax1.set_xlabel(\"Epoche\")\n",
        "        ax1.set_ylabel(\"Loss (log scale)\")\n",
        "        ax1.legend()\n",
        "\n",
        "        #  Visualizzazione Ricostruzione\n",
        "        with torch.no_grad():\n",
        "            def denorm(x):\n",
        "                return x * 0.22 + 0.45\n",
        "\n",
        "            sample_batch = next(iter(val_loader)).to(device)\n",
        "            sample_recon, _, _ = model(sample_batch)\n",
        "\n",
        "            img_orig = denorm(sample_batch[0]).cpu().squeeze().clamp(0, 1)\n",
        "            img_recon = denorm(sample_recon[0]).cpu().squeeze().clamp(0, 1)\n",
        "\n",
        "            ax2.imshow(img_orig, cmap='gray')\n",
        "            ax2.set_title(\"Originale (Denorm)\")\n",
        "            ax2.axis('off')\n",
        "\n",
        "            ax3.imshow(img_recon, cmap='gray')\n",
        "            ax3.set_title(f\"Recon V4 (Epoca {epoch+1})\")\n",
        "            ax3.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Epoca [{epoch+1}/{num_epochs}] | Train: {avg_train:.6f} | Val: {avg_val:.6f} | LR: {current_lr:.1e}\")\n",
        "        print(status_save)"
      ],
      "metadata": {
        "id": "VgUm2VJ9ZtE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# caricamento rapido del modello V4\n",
        "\n",
        "from google.colab import drive\n",
        "import torch\n",
        "\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Definisci dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#  Inizializza il modello V4\n",
        "model = VAE_V4(latent_dim=1024).to(device)\n",
        "\n",
        "# Carica i pesi salvati\n",
        "model_path_v4 = \"/content/drive/MyDrive/VAE_Brain_Project/best_model_v4.pth\"\n",
        "\n",
        "try:\n",
        "    # Caricamento dei pesi\n",
        "    checkpoint = torch.load(model_path_v4, map_location=device)\n",
        "    model.load_state_dict(checkpoint)\n",
        "    model.eval() # modalit√† inferenza\n",
        "    print(f\"‚úÖ Modello V4 caricato correttamente!\")\n",
        "    print(f\"Capacit√† del modello: {sum(p.numel() for p in model.parameters()):,} parametri.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Errore: Il file '{model_path_v4}' non esiste. Devi prima completare almeno un'epoca di training della V4.\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"‚ùå Errore di architettura: Incompatibilit√† tra i pesi salvati e la struttura VAE_V4 definita.\\n{e}\")"
      ],
      "metadata": {
        "id": "Wb60eiksihQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def get_anomaly_scores(model, loader): # funzioine per calcolare errore di ricostruzione\n",
        "    model.eval()\n",
        "    scores = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            recon, _, _ = model(batch)\n",
        "            # Calcolo MSE per ogni immagine nel batch\n",
        "            mse = torch.mean((batch - recon)**2, dim=(1, 2, 3))\n",
        "            scores.extend(mse.cpu().numpy())\n",
        "    return np.array(scores)\n",
        "\n",
        "#  CARICAMENTO MODELLO V4\n",
        "save_path_v4 = \"/content/drive/MyDrive/VAE_Brain_Project/best_model_v4.pth\"\n",
        "try:\n",
        "    model.load_state_dict(torch.load(save_path_v4, map_location=device))\n",
        "    model.eval()\n",
        "    print(f\"‚úÖ Modello V4 caricato correttamente.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Errore caricamento: {e}\")\n",
        "\n",
        "#  Otteniamo i punteggi\n",
        "print(\"Calcolo punteggi di anomalia...\")\n",
        "test_healthy_scores = get_anomaly_scores(model, test_loader_sani)\n",
        "test_anomaly_scores = get_anomaly_scores(model, anno_loader)\n",
        "\n",
        "y_true = np.array([0] * len(test_healthy_scores) + [1] * len(test_anomaly_scores))\n",
        "y_scores = np.concatenate([test_healthy_scores, test_anomaly_scores])\n",
        "\n",
        "#  Calcolo metriche e soglia Youden\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "auc_value = roc_auc_score(y_true, y_scores)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "#  Gestione Inversione e Predizioni\n",
        "is_inverted = np.mean(test_anomaly_scores) < np.mean(test_healthy_scores)\n",
        "if is_inverted:\n",
        "    y_pred = [1 if s < optimal_threshold else 0 for s in y_scores]\n",
        "    display_auc = 1 - auc_value if auc_value < 0.5 else auc_value\n",
        "else:\n",
        "    y_pred = [1 if s > optimal_threshold else 0 for s in y_scores]\n",
        "    display_auc = auc_value\n",
        "\n",
        "#  VISUALIZZAZIONE COMPLETA\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "#  Curva ROC\n",
        "ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {display_auc:.3f}')\n",
        "ax1.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "ax1.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', label='Soglia Ottimale')\n",
        "ax1.set_title('ROC Curve')\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate')\n",
        "ax1.legend(loc=\"lower right\")\n",
        "\n",
        "#  Istogramma Distribuzione Errori\n",
        "ax2.hist(test_healthy_scores, bins=30, alpha=0.5, label='Sani', color='blue', density=True)\n",
        "ax2.hist(test_anomaly_scores, bins=30, alpha=0.5, label='Anomalie', color='red', density=True)\n",
        "ax2.axvline(optimal_threshold, color='green', linestyle='--', label=f'Soglia: {optimal_threshold:.4f}')\n",
        "ax2.set_title('Distribuzione Errori MSE')\n",
        "ax2.set_xlabel('Score Anomalia')\n",
        "ax2.legend()\n",
        "\n",
        "#  Matrice di Confusione\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Sano', 'Anomalia'])\n",
        "disp.plot(ax=ax3, cmap='Blues', values_format='d')\n",
        "ax3.set_title('Matrice di Confusione')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n--- PERFORMANCE REPORT V4 ---\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Sano', 'Anomalia']))"
      ],
      "metadata": {
        "id": "84-T2dCih13T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_debug_comparison(model, loader_sani, loader_anno):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Prendi un esempio sano e uno anomalo\n",
        "        img_sano = next(iter(loader_sani))[0:1].to(device)\n",
        "        img_anno = next(iter(loader_anno))[0:1].to(device)\n",
        "\n",
        "        # Ricostruzioni\n",
        "        rec_sano, _, _ = model(img_sano)\n",
        "        rec_anno, _, _ = model(img_anno)\n",
        "\n",
        "        # Mappe di differenza (errore assoluto)\n",
        "        diff_sano = torch.abs(img_sano - rec_sano)\n",
        "        diff_anno = torch.abs(img_anno - rec_anno)\n",
        "\n",
        "        # Plotting\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "        # Riga Sani\n",
        "        axes[0,0].imshow(img_sano.cpu().squeeze(), cmap='gray'); axes[0,0].set_title(\"Originale SANO\")\n",
        "        axes[0,1].imshow(rec_sano.cpu().squeeze(), cmap='gray'); axes[0,1].set_title(\"Ricostruzione SANO\")\n",
        "        axes[0,2].imshow(diff_sano.cpu().squeeze(), cmap='hot'); axes[0,2].set_title(f\"ERRORE (MSE: {torch.mean(diff_sano**2):.6f})\")\n",
        "\n",
        "        # Riga Anomalie\n",
        "        axes[1,0].imshow(img_anno.cpu().squeeze(), cmap='gray'); axes[1,1].set_title(\"Originale TUMORE\")\n",
        "        axes[1,1].imshow(rec_anno.cpu().squeeze(), cmap='gray'); axes[1,1].set_title(\"Ricostruzione TUMORE\")\n",
        "        axes[1,2].imshow(diff_anno.cpu().squeeze(), cmap='hot'); axes[1,2].set_title(f\"ERRORE (MSE: {torch.mean(diff_anno**2):.6f})\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "plot_debug_comparison(model, test_loader_sani, anno_loader)"
      ],
      "metadata": {
        "id": "zoxDB5QTm_89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modello ha assegnato correttamente i labels?\n",
        "def check_labels_integrity(file_sani_test, file_anomalie_test):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Prendi il primo file della lista test sani\n",
        "    img_sana_path = file_sani_test[0]\n",
        "    img_sana = Image.open(img_sana_path).convert('L')\n",
        "\n",
        "    # Prendi il primo file della lista anomalie\n",
        "    img_anno_path = file_anomalie_test[0]\n",
        "    img_anno = Image.open(img_anno_path).convert('L')\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_sana, cmap='gray')\n",
        "    plt.title(f\"LABEL: SANO\\nPath: ...{img_sana_path[-30:]}\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(img_anno, cmap='gray')\n",
        "    plt.title(f\"LABEL: ANOMALIA\\nPath: ...{img_anno_path[-30:]}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Usiamo le liste originali dei file per il controllo\n",
        "check_labels_integrity(test_healthy_subset.dataset.file_list, file_anomalie)"
      ],
      "metadata": {
        "id": "u5bUqc4poDAn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}